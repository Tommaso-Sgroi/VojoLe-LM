{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKooa4fDI4BR"
   },
   "source": [
    "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
    "<div class=\"align-center\">\n",
    "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
    "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
    "</div>\n",
    "\n",
    "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
    "\n",
    "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uixDWKZeI4BV"
   },
   "source": [
    "### News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9JQH4-AI4BV"
   },
   "source": [
    "**NEW** Unsloth now supports training the new **gpt-oss** model from OpenAI! You can start finetune gpt-oss for free with our **[Colab notebook](https://x.com/UnslothAI/status/1953896997867729075)**!\n",
    "\n",
    "Unsloth now supports Text-to-Speech (TTS) models. Read our [guide here](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning).\n",
    "\n",
    "Read our **[Gemma 3N Guide](https://docs.unsloth.ai/basics/gemma-3n-how-to-run-and-fine-tune)** and check out our new **[Dynamic 2.0](https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs)** quants which outperforms other quantization methods!\n",
    "\n",
    "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3gdqwgMI4BV"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jdobfpm7I4BW"
   },
   "source": [
    "%%capture\n",
    "import os, re, json\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
    "    xformers = \"xformers==\" + \"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\"\n",
    "    !pip install torchmetrics\n",
    "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4paFn-HN6sy"
   },
   "source": [
    "### Google Drive Login\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mva2QjUtOA4I",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f0b0f5b1-f152-4aa1-a82a-80b1c2621d5f"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jg1NhnRBI4BX"
   },
   "source": [
    "\n",
    "## Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHNaR--CI4BX"
   },
   "source": [
    "#### Text Completion / Raw Text Training\n",
    "This is a community notebook collaboration with [Mithex].\n",
    "\n",
    "We train on `Tiny Stories` (link [here](https://huggingface.co/datasets/roneneldan/TinyStories)) which is a collection of small stories. For example:\n",
    "```\n",
    "Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun.\n",
    "Beep was a healthy car because he always had good fuel....\n",
    "```\n",
    "Instead of `Alpaca`'s Question Answer format, one only needs 1 column - the `\"text\"` column. This means you can finetune on any dataset and let your model act as a text completion model, like for novel writing.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "31gGrDvUI4BX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "de433148-fca2-4abc-a363-466811181602"
   },
   "source": [
    "%env UNSLOTH_RETURN_LOGITS=1 # Run this to disable CCE since it is not supported for CPT\n",
    "%env SAVE_MODEL_PATH=./outputs/best"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QmUBVEnvCDJv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5053a824-eccd-4c03-cd6d-9b5ab94351b2"
   },
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",      # New Mistral v3 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/llama-3-8b-bnb-4bit\",           # Llama-3 15 trillion tokens model 2x faster!\n",
    "    \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    \"unsloth/llama-3-70b-bnb-4bit\",\n",
    "    \"unsloth/Phi-3-mini-4k-instruct\",        # Phi-3 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/mistral-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-bnb-4bit\",             # Gemma 2.2x faster!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-270m-it-unsloth-bnb-4bit\", # \"unsloth/mistral-7b\" for 16bit loading\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXd9bTZd1aaL"
   },
   "source": [
    "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!\n",
    "\n",
    "We also add `embed_tokens` and `lm_head` to allow the model to learn out of distribution data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6bZsfBuZDeCL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "49bba626-a7f0-4c4b-d75c-08a3623f22fc"
   },
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 32, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 69420,\n",
    "    use_rslora = True,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vITh0KVJ10qX"
   },
   "source": [
    "<a name=\"Data\"></a>\n",
    "### Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!#npm install jsonrepair\n",
    "!#pip install pythonmonkey\n",
    "\n",
    "with open('/content/drive/MyDrive/Deep learning/Project/dataset_sorianese.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = data['train']\n",
    "test_dataset = data['test']\n",
    "validation_dataset = data['validation']\n",
    "\n",
    "\"\"\"\n",
    "for i in range(3):\n",
    "  print(train[i], test[i], validation[i], end='\\n\\n', sep='\\n')\n",
    "\n",
    "import pythonmonkey, json\n",
    "jsonrepair = pythonmonkey.require('jsonrepair').jsonrepair\n",
    "mydataset=[]; malformatted=0\n",
    "with open('/content/drive/MyDrive/Deep learning/Project/dataset_sorianese1.json', 'w', encoding='utf-8') as f:\n",
    "  for split_type, ds in enumerate([train, test, validation]):\n",
    "    for d in ds:\n",
    "      try:\n",
    "        d['sentence_text'] = json.loads(d['sentence_text'])['translation']\n",
    "      except:\n",
    "        try:\n",
    "          d['sentence_text'] = json.loads(jsonrepair(d['sentence_text']))['translation']\n",
    "        except:\n",
    "            malformatted += 1\n",
    "      del d['IsLocked'], d['evaluated'], d['split']\n",
    "    print(malformatted)\n",
    "  data = {\n",
    "    'train': train,\n",
    "    'test': test,\n",
    "    'validation': validation\n",
    "  }\n",
    "  json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "  \"\"\"\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompts_func(example):\n",
    "    return { \"text\" : example[\"sentence_text\"] + EOS_TOKEN }\n",
    "train_dataset = list(map(formatting_prompts_func, train_dataset))\n",
    "test_dataset = list(map(formatting_prompts_func, test_dataset))\n",
    "validation_dataset = list(map(formatting_prompts_func, validation_dataset))\n",
    "print('Dataset loaded')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e949iQzq83J7",
    "outputId": "7ea53b8a-b91b-40f3-e7a1-3588cee0782f"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ENCwwLaWjud"
   },
   "source": [
    "Print out 5 sentences."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMv7nqxz6fta",
    "outputId": "fa2de1d7-c315-4af2-f8fb-d4d0bf1fc76a"
   },
   "source": [
    "for row in train_dataset[:5]:\n",
    "    print(\"=========================\")\n",
    "    print(row[\"text\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idAEIeSQ3xdS"
   },
   "source": [
    "<a name=\"Train\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1ee0062",
    "outputId": "6a24ebed-e46f-4f37-efc9-0fd0240081b1"
   },
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_list(train_dataset[:3000])\n",
    "test_dataset = Dataset.from_list(test_dataset[:300])\n",
    "validation_dataset = Dataset.from_list(validation_dataset[:30])\n",
    "\n",
    "# You can display the structure of the datasets to verify\n",
    "print(\"Train dataset structure:\")\n",
    "print(train_dataset)\n",
    "print(\"\\nValidation dataset structure:\")\n",
    "print(validation_dataset)\n",
    "print(\"\\nTest dataset structure:\")\n",
    "print(test_dataset)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Add Callback to calculate Perplexity\n"
   ],
   "metadata": {
    "id": "owc-bWNVPd03"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Trainer\n",
    "We prepare the train/validation with Hyperparameters."
   ],
   "metadata": {
    "id": "i9cLqYrG581i"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback, EvalPrediction, TrainerCallback\n",
    "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n"
   ],
   "metadata": {
    "id": "2I2zkG-ODJO1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98,
     "referenced_widgets": [
      "e998e752390849f0af93afbf5a9336d5",
      "b7c20d8fa7e44cfd9ef538938569d4c8",
      "7dd970684b194b2d8ec5c0a72f51ddc4",
      "a167e0af483047a4b67b85b8d9cf746a",
      "27a6c40d35da484882c6b4cbe2177a23",
      "734b681e39464e4492e2471e100c0d18",
      "58599504465449fcb6bd0c4f73fa262c",
      "5a09e27a9d04428dac9b705c86ba7b2c",
      "5c0ea49b2c55481aa7321dd177aa120f",
      "9644af834e7c4e40ad8330932b43fbc1",
      "5a6fd42ef07a4896a64ff11481f6adbd",
      "676d2625670148229f41fafeb6864011",
      "0924ec77db904e9f8ac498a5fa0c8c80",
      "235c3e4dca9b4b959311647fdc2d70eb",
      "02a3b082a93d4736828f2ea2155a7b25",
      "5073b9f7acc943ec8a6d61dba798afc8",
      "55747ee23c064974a7a7debe43620aab",
      "06fd43369ff54c099978f86d1bcb1756",
      "e706d2857da7457ba8513a587f7b0fe3",
      "9f0675a5f2bf4fe0bc3a99a81235c41a",
      "ccc71c3832dd4831b178dfd59bdc7acd",
      "de74b9d10d254ec6ab322ee5afcdeb04"
     ]
    },
    "id": "95_Nn-89DhsL",
    "outputId": "dbf48653-2d11-4df7-e1f9-a6e372423d36"
   },
   "source": [
    "\n",
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = validation_dataset,\n",
    "    eval_dataset = validation_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 8,\n",
    "    save_total_limit = 1,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    args = UnslothTrainingArguments(\n",
    "\n",
    "        per_device_train_batch_size = 5,\n",
    "        gradient_accumulation_steps = 1,\n",
    "\n",
    "        warmup_ratio = 0.1,\n",
    "        num_train_epochs = 25,\n",
    "\n",
    "        learning_rate = 5e-5,\n",
    "        embedding_learning_rate = 5e-6,\n",
    "\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.00,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 42069,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        greater_is_better=False,\n",
    "    ),\n",
    "\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=10)],\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Raw Perplexity on Untrained Model"
   ],
   "metadata": {
    "id": "CHBVM6T2AkJa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate the currently loaded and trained model on the test dataset\n",
    "test_results = trainer.evaluate() # (eval_dataset=validation_dataset)\n",
    "print(test_results)\n",
    "# The test loss will be in the results\n",
    "test_loss = test_results[\"eval_loss\"]\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Calculate perplexity from the test loss\n",
    "import numpy as np\n",
    "test_perplexity = np.exp(test_loss)\n",
    "print(f\"Test Perplexity: {test_perplexity}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "ezCflqxC_yeb",
    "outputId": "82435f05-36e4-4be5-ed01-7bd3a03418d4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train\n",
    "\n",
    "By now, we are going to train our model's on the Dataset, at the end of the train we save the best model found during training."
   ],
   "metadata": {
    "id": "yysm-DwxeBzX"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ejIt2xSNKKp",
    "outputId": "a0a23a40-2558-4201-ff88-71283ad395a2"
   },
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 984
    },
    "id": "yqxqAZ7KJ4oL",
    "outputId": "b356fcf6-e850-4a34-8baf-133b1bb81993"
   },
   "source": [
    "trainer_stats = trainer.train()\n",
    "trainer.save_model(os.getenv('SAVE_MODEL_PATH'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71abca22",
    "outputId": "7c83a678-d356-4fce-d224-f08b6d9b4187"
   },
   "source": [
    "# Access the training log history\n",
    "log_history = trainer.state.log_history\n",
    "print(log_history)\n",
    "# Print the full log history\n",
    "print(json.dumps(log_history, indent=2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Just Evaluation\n",
    "We are going to evaluate various models on the completion task using the test dataset. We calculate the Perplexity upon the validation dataset."
   ],
   "metadata": {
    "id": "QZrMN-RIz33h"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCqnaKmlO1U9",
    "outputId": "d47eddab-36dd-4cc4-db35-d98ee777b026"
   },
   "source": [
    "# @title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate the currently loaded and trained model on the test dataset\n",
    "test_results = trainer.evaluate() # (eval_dataset=validation_dataset)\n",
    "print(test_results)\n",
    "# The test loss will be in the results\n",
    "test_loss = test_results[\"eval_loss\"]\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Calculate perplexity from the test loss\n",
    "import numpy as np\n",
    "test_perplexity = np.exp(test_loss)\n",
    "print(f\"Test Perplexity: {test_perplexity}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "dUxibU3Z5kYN",
    "outputId": "3ecea376-e9bd-4a34-9091-d640bac3718d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference"
   ],
   "metadata": {
    "id": "5f1fQhxSA04i"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### check what you deleted!! 2 cells"
   ],
   "metadata": {
    "id": "JJZ0yGgUyBaW"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekOmTR1hSNcr"
   },
   "source": [
    "<a name=\"Inference\"></a>\n",
    "### Inference\n",
    "Let's run the model!\n",
    "\n",
    "We first will try to see if the model follows the style and understands to write a story that is within the distribution of \"Tiny Stories\". Ie a story fit for a bed time story most likely.\n",
    "\n",
    "We select \"Once upon a time, in a galaxy, far far away,\" since it normally is associated with Star Wars."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHm11vaQRt1U",
    "outputId": "b7c3956b-2926-4892-c8f0-f1ecb4015440"
   },
   "source": [
    "from transformers import TextIteratorStreamer\n",
    "from threading import Thread\n",
    "text_streamer = TextIteratorStreamer(tokenizer)\n",
    "import textwrap\n",
    "max_print_width = 100\n",
    "\n",
    "# Before running inference, call `FastLanguageModel.for_inference` first\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    \"Once upon a time, in a galaxy, far far away,\"\n",
    "]*1, return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "generation_kwargs = dict(\n",
    "    inputs,\n",
    "    streamer = text_streamer,\n",
    "    max_new_tokens = 256,\n",
    "    use_cache = True,\n",
    ")\n",
    "thread = Thread(target = model.generate, kwargs = generation_kwargs)\n",
    "thread.start()\n",
    "\n",
    "length = 0\n",
    "for j, new_text in enumerate(text_streamer):\n",
    "    if j == 0:\n",
    "        wrapped_text = textwrap.wrap(new_text, width = max_print_width)\n",
    "        length = len(wrapped_text[-1])\n",
    "        wrapped_text = \"\\n\".join(wrapped_text)\n",
    "        print(wrapped_text, end = \"\")\n",
    "    else:\n",
    "        length += len(new_text)\n",
    "        if length >= max_print_width:\n",
    "            length = 0\n",
    "            print()\n",
    "        print(new_text, end = \"\")\n",
    "    pass\n",
    "pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I38SUY7dI4Bb"
   },
   "source": [
    "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
    "\n",
    "Some other links:\n",
    "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
    "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
    "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
    "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
    "\n",
    "<div class=\"align-center\">\n",
    "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
    "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
    "\n",
    "  Join Discord if you need help + ⭐️ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐️\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "collapsed_sections": [
    "Jg1NhnRBI4BX",
    "vITh0KVJ10qX",
    "CHBVM6T2AkJa",
    "ekOmTR1hSNcr"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "e998e752390849f0af93afbf5a9336d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b7c20d8fa7e44cfd9ef538938569d4c8",
       "IPY_MODEL_7dd970684b194b2d8ec5c0a72f51ddc4",
       "IPY_MODEL_a167e0af483047a4b67b85b8d9cf746a"
      ],
      "layout": "IPY_MODEL_27a6c40d35da484882c6b4cbe2177a23"
     }
    },
    "b7c20d8fa7e44cfd9ef538938569d4c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_734b681e39464e4492e2471e100c0d18",
      "placeholder": "​",
      "style": "IPY_MODEL_58599504465449fcb6bd0c4f73fa262c",
      "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=2): 100%"
     }
    },
    "7dd970684b194b2d8ec5c0a72f51ddc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a09e27a9d04428dac9b705c86ba7b2c",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5c0ea49b2c55481aa7321dd177aa120f",
      "value": 30
     }
    },
    "a167e0af483047a4b67b85b8d9cf746a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9644af834e7c4e40ad8330932b43fbc1",
      "placeholder": "​",
      "style": "IPY_MODEL_5a6fd42ef07a4896a64ff11481f6adbd",
      "value": " 30/30 [00:05&lt;00:00,  6.09 examples/s]"
     }
    },
    "27a6c40d35da484882c6b4cbe2177a23": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "734b681e39464e4492e2471e100c0d18": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58599504465449fcb6bd0c4f73fa262c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a09e27a9d04428dac9b705c86ba7b2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c0ea49b2c55481aa7321dd177aa120f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9644af834e7c4e40ad8330932b43fbc1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a6fd42ef07a4896a64ff11481f6adbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "676d2625670148229f41fafeb6864011": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0924ec77db904e9f8ac498a5fa0c8c80",
       "IPY_MODEL_235c3e4dca9b4b959311647fdc2d70eb",
       "IPY_MODEL_02a3b082a93d4736828f2ea2155a7b25"
      ],
      "layout": "IPY_MODEL_5073b9f7acc943ec8a6d61dba798afc8"
     }
    },
    "0924ec77db904e9f8ac498a5fa0c8c80": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55747ee23c064974a7a7debe43620aab",
      "placeholder": "​",
      "style": "IPY_MODEL_06fd43369ff54c099978f86d1bcb1756",
      "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=2): 100%"
     }
    },
    "235c3e4dca9b4b959311647fdc2d70eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e706d2857da7457ba8513a587f7b0fe3",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f0675a5f2bf4fe0bc3a99a81235c41a",
      "value": 30
     }
    },
    "02a3b082a93d4736828f2ea2155a7b25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccc71c3832dd4831b178dfd59bdc7acd",
      "placeholder": "​",
      "style": "IPY_MODEL_de74b9d10d254ec6ab322ee5afcdeb04",
      "value": " 30/30 [00:05&lt;00:00,  6.29 examples/s]"
     }
    },
    "5073b9f7acc943ec8a6d61dba798afc8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55747ee23c064974a7a7debe43620aab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06fd43369ff54c099978f86d1bcb1756": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e706d2857da7457ba8513a587f7b0fe3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f0675a5f2bf4fe0bc3a99a81235c41a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ccc71c3832dd4831b178dfd59bdc7acd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de74b9d10d254ec6ab322ee5afcdeb04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
